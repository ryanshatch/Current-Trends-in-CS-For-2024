#### Hidden biases can exist and display this in popular applications mostly because of the way that the data is selected or processed. 
> For example, facial recognition software usually has a higher amount of errors with people of color because the training datasets are found to have slightly skewed towards faces with lighter skin color. Another example of AI displaying racism and sexism within hidden biases, is the ruicruiting tools that Amazon uses and how it shows a bias towards men applicants.

#### To address these problems there are several practices that are quickly growing in popularity to help aid against the racist and sexist biases that models might have by default. 
> For example, Responsible Research and Innovation and Ethics by Design both are known to blend ethical considerations into every stage of development. Also, at least trying to apply new guidelines and policies, for example the “right to be forgotten,” comes with the ability to give people the choice on whether or not to keep or not store any personal data. Although there might be some slight cons to this, it still is a good way to remove any level of biases from the model while also keeping your data safe, restricted, all while not allowing your inputs or prompts to influence the model or train it with your personal biases. 
<br>
<br>
#### Using more and more diverse datasets and frameworks like RRI helps to build models and systems that actively push back against bias and tailor technology to become more fair, open, and responsible.
> https://customerthink.com/how-to-keep-bias-out-of-your-ai-models/
> https://web.archive.org/web/20240710160510/https://f8federal.com/overcome-and-prevent-ai-bias/
> https://www.vox.com/recode/2020/2/18/21121286/algorithms-bias-discrimination-facial-recognition-transparency

<!-- Hidden biases can exist and display this in popular applications mostly because of the way that the data is selected or processed. For example, facial recognition software usually has a higher amount of errors with people of color because the training datasets are found to have slightly skewed towards faces with lighter skin color. Another example of AI displaying racism and sexism within hidden biases, is the ruicruiting tools that Amazon uses and how it shows a bias towards men applicants.

To address these problems there are several practices that are quickly growing in popularity to help aid against the racist and sexist biases that models might have by default. For example, Responsible Research and Innovation and Ethics by Design both are known to blend ethical considerations into every stage of development. Also, at least trying to apply new guidelines and policies, for example the “right to be forgotten,” comes with the ability to give people the choice on whether or not to keep or not store any personal data. Although there might be some slight cons to this, it still is a good way to remove any level of biases from the model while also keeping your data safe, restricted, all while not allowing your inputs or prompts to influence the model or train it with your personal biases. 


Using more and more diverse datasets and frameworks like RRI helps to build models and systems that actively push back against bias and tailor technology to become more fair, open, and responsible.

https://customerthink.com/how-to-keep-bias-out-of-your-ai-models/

https://web.archive.org/web/20240710160510/https://f8federal.com/overcome-and-prevent-ai-bias/

https://www.vox.com/recode/2020/2/18/21121286/algorithms-bias-discrimination-facial-recognition-transparency -->